{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/michaelscutari/mic\n",
      "[nltk_data]     romamba/envs/cs671/lib/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/michaelscutari/micro\n",
      "[nltk_data]     mamba/envs/cs671/lib/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/michaelscutari/mic\n",
      "[nltk_data]     romamba/envs/cs671/lib/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Imports ----\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from rake_nltk import Rake\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Welcome to Bed-Stuy, Brooklyn! Our newly renov...\n",
      "1    Lovely nonsmoking annex in Brooklyn's \"secret ...\n",
      "2    This studio presents unparalleled convenience ...\n",
      "3    - Furnished room in a newly renovated apartmen...\n",
      "4    This modern property in Manhattan is just step...\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ---- Import Data ----\n",
    "data = pd.read_csv('../data/train.csv')\n",
    "descriptions = data['description']\n",
    "\n",
    "print(descriptions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nmf_feature_1  nmf_feature_2  ...  nmf_feature_39  nmf_feature_40\n",
      "0       0.004458            0.0  ...        0.000000        0.001122\n",
      "1       0.000465            0.0  ...        0.004788        0.032576\n",
      "2       0.000088            0.0  ...        0.000000        0.015328\n",
      "3       0.003704            0.0  ...        0.000000        0.000000\n",
      "4       0.000000            0.0  ...        0.060400        0.000000\n",
      "\n",
      "[5 rows x 40 columns]\n",
      "nmf_feature_1: ['minute', 'minute walk', 'airport', 'walk', 'train', 'jfk', 'minute away', 'manhattan']\n",
      "nmf_feature_2: ['nan', 'zoo', 'facing', 'filled', 'ferry', 'feel like', 'feel home', 'feel']\n",
      "nmf_feature_3: ['building', 'elevator', 'view', 'elevator building', 'laundry', 'floor', 'located', 'central']\n",
      "nmf_feature_4: ['br', 'br br', 'br apartment', 'please', 'br min', 'br located', 'hotel', 'br please']\n",
      "nmf_feature_5: ['comfort', 'perfect', 'offer', 'heart', 'city', 'modern', 'vibrant', 'welcome']\n",
      "nmf_feature_6: ['private', 'bathroom', 'private bathroom', 'room', 'private room', 'entrance', 'private bedroom', 'shared']\n",
      "nmf_feature_7: ['place', 'stay', 'place stay', 'comfortable', 'youll', 'great', 'time', 'perfect']\n",
      "nmf_feature_8: ['living', 'support', 'apartment fullyequipped', 'room dedicated', 'fullyequipped kitchen', 'simply show', 'ontheground', 'itll easy']\n",
      "nmf_feature_9: ['rent', 'offer', 'rent room', 'communityoriented coliving', 'communityoriented', 'even within', 'easiest', 'way rent']\n",
      "nmf_feature_10: ['york', 'new york', 'new', 'york city', 'city', 'location', 'iconic', 'fee']\n",
      "nmf_feature_11: ['offer id', 'wherever choose', 'choose live', 'blueground youll', 'home wherever', 'live blueground', 'youre close', 'decor fully']\n",
      "nmf_feature_12: ['furnished beautifully', 'day one', 'love coming', 'living day', 'designed fullyequipped', 'home thoughtfully', 'coming home', 'thoughtfully furnished']\n",
      "nmf_feature_13: ['back relax', 'kick', 'kick back', 'calm', 'relax calm', 'back', 'calm stylish', 'relax']\n",
      "nmf_feature_14: ['square', 'time', 'time square', 'empire', 'state', 'empire state', 'state building', 'central']\n",
      "nmf_feature_15: ['easy access', 'access', 'easy', 'enjoy easy', 'access everything', 'centrally', 'centrally located', 'everything centrally']\n",
      "nmf_feature_16: ['enjoy stylish', 'stylish experience', 'experience centrallylocated', 'centrallylocated', 'stylish', 'experience', 'centrallylocated place', 'enjoy']\n",
      "nmf_feature_17: ['min', 'min walk', 'walk', 'train', 'train min', 'min manhattan', 'br min', 'manhattan min']\n",
      "nmf_feature_18: ['spacious serene', 'forget worry', 'worry', 'worry spacious', 'forget', 'serene space', 'serene', 'spacious']\n",
      "nmf_feature_19: ['ave', 'desk chair', 'chair', 'room', 'desk', 'onetime room', 'cleaning administration', 'room cleaning']\n",
      "nmf_feature_20: ['clean', 'area', 'month', 'common', 'shared', 'common area', 'fast wifi', 'fast']\n",
      "nmf_feature_21: ['bed', 'queen', 'size', 'size bed', 'full', 'queen size', 'large', 'tv']\n",
      "nmf_feature_22: ['fully', 'equipped', 'fully equipped', 'equipped kitchen', 'complimentary', 'service', 'furnished', 'wifi']\n",
      "nmf_feature_23: ['restaurant', 'bar', 'shop', 'neighborhood', 'restaurant bar', 'great', 'store', 'cafe']\n",
      "nmf_feature_24: ['peaceful centrallylocated', 'simple peaceful', 'keep simple', 'simple', 'peaceful', 'keep', 'centrallylocated', 'centrallylocated place']\n",
      "nmf_feature_25: ['walking', 'distance', 'walking distance', 'within walking', 'within', 'bus', 'located', 'manhattan']\n",
      "nmf_feature_26: ['subway', 'line', 'subway line', 'st', 'station', 'major', 'step away', 'major subway']\n",
      "nmf_feature_27: ['step', 'establishment', 'outpost', 'premier', 'fully furnished', 'managed', 'club', 'creative']\n",
      "nmf_feature_28: ['family', 'whole family', 'whole', 'peaceful place', 'relax', 'peaceful', 'fun', 'bring']\n",
      "nmf_feature_29: ['available', 'room', 'room available', 'clean', 'spacious', 'shortterm', 'rent', 'also']\n",
      "nmf_feature_30: ['block', 'away', 'block away', 'train', 'one', 'one block', 'park', 'two']\n",
      "nmf_feature_31: ['bathroom', 'cooking', 'share', 'bedroom bathroom', 'room', 'floorbr', 'use', 'dish']\n",
      "nmf_feature_32: ['close', 'everything', 'close everything', 'family', 'stay', 'need', 'centrallylocated', 'everything need']\n",
      "nmf_feature_33: ['brooklyn', 'prospect', 'prospect park', 'garden', 'park', 'brownstone', 'museum', 'height']\n",
      "nmf_feature_34: ['apartment', 'bedroom', 'bedroom apartment', 'apartment located', 'br apartment', 'spacious', 'beautiful', 'two']\n",
      "nmf_feature_35: ['unique', 'take', 'tranquil', 'getaway', 'easy', 'style', 'place', 'make']\n",
      "nmf_feature_36: ['side', 'east', 'upper', 'east side', 'upper east', 'central park', 'central', 'museum']\n",
      "nmf_feature_37: ['renovated', 'newly', 'newly renovated', 'appliance', 'renovated bedroom', 'new', 'brand', 'brand new']\n",
      "nmf_feature_38: ['home', 'away home', 'home away', 'away', 'feel', 'enjoy', 'welcome', 'quiet']\n",
      "nmf_feature_39: ['property', 'rove', 'modern', 'designed', 'flatscreen', 'free', 'concierge', 'flatscreen tv']\n",
      "nmf_feature_40: ['guest', 'space', 'host', 'please', 'unit', 'shared', 'present', 'note']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_extract_nmf_features(df, \n",
    "                                        description_col='description', \n",
    "                                        n_components=40, \n",
    "                                        max_features=1000, \n",
    "                                        random_state=42,\n",
    "                                        top_n_words=8):\n",
    "    \"\"\"\n",
    "    Preprocesses the 'description' column of a pandas DataFrame, extracts NMF features,\n",
    "    and identifies top contributing words for each NMF component.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame containing the 'description' column.\n",
    "    - description_col (str): The name of the column containing property descriptions.\n",
    "    - n_components (int): Number of NMF components to extract.\n",
    "    - max_features (int): Maximum number of features for the TF-IDF vectorizer.\n",
    "    - random_state (int): Random state for reproducibility.\n",
    "    - top_n_words (int): Number of top words to display for each NMF component.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame containing the NMF features.\n",
    "    - TfidfVectorizer: The fitted TF-IDF vectorizer.\n",
    "    - NMF: The fitted NMF model.\n",
    "    - dict: A dictionary with top words for each NMF component.\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.decomposition import NMF\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    import re\n",
    "    \n",
    "    # Initialize stopwords and lemmatizer\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def clean_text(text):\n",
    "        # Lowercase\n",
    "        text = text.lower()\n",
    "        # Remove punctuation and non-alphabetic characters\n",
    "        text = re.sub(r'[^a-z\\s]', '', text)\n",
    "        # Tokenize\n",
    "        tokens = text.split()\n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "        # Join back into string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    # Apply text cleaning\n",
    "    df['clean_description'] = df[description_col].astype(str).apply(clean_text)\n",
    "    \n",
    "    # Initialize TF-IDF Vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=max_features,\n",
    "                                       ngram_range=(1, 2))  \n",
    "    \n",
    "    # Fit and transform the clean descriptions\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['clean_description'])\n",
    "    \n",
    "    # Initialize and fit NMF\n",
    "    nmf_model = NMF(n_components=n_components, random_state=random_state)\n",
    "    nmf_features = nmf_model.fit_transform(tfidf_matrix)\n",
    "    \n",
    "    # Create a DataFrame for NMF features\n",
    "    nmf_feature_names = [f'nmf_feature_{i+1}' for i in range(n_components)]\n",
    "    nmf_df = pd.DataFrame(nmf_features, columns=nmf_feature_names, index=df.index)\n",
    "    \n",
    "    # Extract top words for each NMF component\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    top_words_dict = {}\n",
    "    for i, topic in enumerate(nmf_model.components_):\n",
    "        top_indices = topic.argsort()[::-1][:top_n_words]\n",
    "        top_words = [feature_names[j] for j in top_indices]\n",
    "        top_words_dict[f'nmf_feature_{i+1}'] = top_words\n",
    "    \n",
    "    return nmf_df, tfidf_vectorizer, nmf_model, top_words_dict\n",
    "\n",
    "# Extract NMF features\n",
    "nmf_df, tfidf_vectorizer, nmf_model, top_words_dict = preprocess_and_extract_nmf_features(data)\n",
    "\n",
    "# Display NMF features\n",
    "print(nmf_df.head())\n",
    "\n",
    "# Display top words for each NMF component\n",
    "for feature, words in top_words_dict.items():\n",
    "    print(f'{feature}: {words}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nmf_feature_39    0.202113\n",
      "nmf_feature_8     0.165156\n",
      "nmf_feature_12    0.165137\n",
      "nmf_feature_11    0.163946\n",
      "nmf_feature_5     0.151474\n",
      "nmf_feature_14    0.133378\n",
      "nmf_feature_3     0.095600\n",
      "nmf_feature_36    0.072483\n",
      "nmf_feature_4     0.034960\n",
      "nmf_feature_22    0.034727\n",
      "nmf_feature_16    0.029955\n",
      "nmf_feature_33    0.011914\n",
      "nmf_feature_37    0.005079\n",
      "nmf_feature_15    0.004216\n",
      "nmf_feature_28    0.001574\n",
      "nmf_feature_34    0.000086\n",
      "nmf_feature_10   -0.002596\n",
      "nmf_feature_21   -0.009811\n",
      "nmf_feature_38   -0.011828\n",
      "nmf_feature_2    -0.012553\n",
      "nmf_feature_40   -0.015353\n",
      "nmf_feature_13   -0.015429\n",
      "nmf_feature_25   -0.015988\n",
      "nmf_feature_26   -0.019187\n",
      "nmf_feature_35   -0.021108\n",
      "nmf_feature_23   -0.022635\n",
      "nmf_feature_7    -0.027408\n",
      "nmf_feature_18   -0.039716\n",
      "nmf_feature_32   -0.039933\n",
      "nmf_feature_24   -0.043949\n",
      "nmf_feature_30   -0.048784\n",
      "nmf_feature_20   -0.099736\n",
      "nmf_feature_27   -0.100438\n",
      "nmf_feature_29   -0.111710\n",
      "nmf_feature_6    -0.119532\n",
      "nmf_feature_1    -0.126186\n",
      "nmf_feature_9    -0.126557\n",
      "nmf_feature_17   -0.150582\n",
      "nmf_feature_31   -0.167221\n",
      "nmf_feature_19   -0.215126\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assume nmf_features is a NumPy array of shape (n_samples, n_topics)\n",
    "nmf_features_df = nmf_df.copy()\n",
    "nmf_features_df['price'] = data['price'].values\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = nmf_features_df.corr()\n",
    "\n",
    "# Extract correlations with price\n",
    "topic_price_correlations = correlation_matrix['price'][:-1]  # Exclude the 'price' correlation with itself\n",
    "\n",
    "# Display correlations\n",
    "print(topic_price_correlations.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['stay', 'welcome', 'train', 'room', 'apartment', 'start living', 'nan',\n",
      "       'relax', 'home', 'city', 'spacious', 'step', 'need', 'minute', 'enjoy',\n",
      "       'subway', 'heart', 'onetime room cleaning', 'minute walk', 'step away'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_extract_rake_features(df, \n",
    "                                         description_col='description', \n",
    "                                         max_keywords=10, \n",
    "                                         min_keyword_length=1,\n",
    "                                         max_features=1000):\n",
    "    \"\"\"\n",
    "    Preprocesses the 'description' column of a pandas DataFrame, extracts RAKE keywords,\n",
    "    and transforms them into a feature matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame containing the 'description' column.\n",
    "    - description_col (str): Name of the column with property descriptions.\n",
    "    - max_keywords (int): Maximum number of keywords to extract per description.\n",
    "    - min_keyword_length (int): Minimum number of words in a keyword.\n",
    "    - max_features (int): Maximum number of unique keywords to consider as features.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame containing RAKE features.\n",
    "    - Rake: The fitted RAKE object.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize RAKE with English stopwords and specify minimum keyword length\n",
    "    rake = Rake(stopwords=stopwords.words('english'), \n",
    "                min_length=min_keyword_length, \n",
    "                max_length=5)  # You can adjust max_length based on your data\n",
    "    \n",
    "    # Initialize lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def clean_text(text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-z\\s]', '', text)\n",
    "        # remove words in more than 90% of the documents\n",
    "        text = re.sub(r'\\b\\w{1,2}\\b', '', text)\n",
    "        return text\n",
    "    \n",
    "    def lemmatize_keywords(keywords):\n",
    "        return [' '.join([lemmatizer.lemmatize(word) for word in keyword.split()]) for keyword in keywords]\n",
    "    \n",
    "    # Clean descriptions\n",
    "    df['clean_description'] = df[description_col].astype(str).apply(clean_text)\n",
    "    \n",
    "    # Extract keywords using RAKE\n",
    "    def extract_keywords(text):\n",
    "        rake.extract_keywords_from_text(text)\n",
    "        keywords_with_scores = rake.get_ranked_phrases_with_scores()\n",
    "        # Sort by score descending and take top N keywords\n",
    "        sorted_keywords = sorted(keywords_with_scores, key=lambda x: x[0], reverse=True)\n",
    "        top_keywords = [kw for score, kw in sorted_keywords[:max_keywords]]\n",
    "        # Lemmatize keywords\n",
    "        lemmatized = lemmatize_keywords(top_keywords)\n",
    "        return lemmatized\n",
    "    \n",
    "    df['keywords'] = df['clean_description'].apply(extract_keywords)\n",
    "    \n",
    "    # Flatten the list of keywords to find the most common ones\n",
    "    all_keywords = [keyword for sublist in df['keywords'] for keyword in sublist]\n",
    "    # Optionally, you can apply frequency filtering here\n",
    "    # For simplicity, we'll select the top 'max_features' most common keywords\n",
    "    from collections import Counter\n",
    "    keyword_counts = Counter(all_keywords)\n",
    "    most_common_keywords = [kw for kw, count in keyword_counts.most_common(max_features)]\n",
    "    \n",
    "    # Initialize a keyword extractor based on the most common keywords\n",
    "    # Create binary features indicating the presence of keywords\n",
    "    def keyword_features(keywords):\n",
    "        features = {}\n",
    "        for kw in most_common_keywords:\n",
    "            features[kw] = 1 if kw in keywords else 0\n",
    "        return features\n",
    "    \n",
    "    # Apply to the DataFrame\n",
    "    rake_features_df = pd.DataFrame(df['keywords'].apply(keyword_features).tolist()).fillna(0)\n",
    "    \n",
    "    # Optionally, you can keep the original DataFrame unchanged and return only the features\n",
    "    return rake_features_df, rake\n",
    "\n",
    "# Apply RAKE feature extraction\n",
    "rake_features_df, rake = preprocess_and_extract_rake_features(\n",
    "    data, \n",
    "    description_col='description', \n",
    "    max_keywords=10,        # Extract top 5 keywords per description\n",
    "    min_keyword_length=1,  # Minimum 1 word per keyword\n",
    "    max_features=20        # Consider top 20 most common keywords as features\n",
    ")\n",
    "\n",
    "# Display RAKE features\n",
    "print(rake_features_df.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
